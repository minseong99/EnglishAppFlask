# app.py
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
from fastapi.responses import JSONResponse
import base64, io, os, logging, traceback
import numpy as np
import torch, wave
from TTS.api import TTS
import uvicorn

app = FastAPI()
logging.basicConfig(level=logging.INFO)

# ğŸš€ GPU í™œì„±í™” (ê°€ëŠ¥í•œ ê²½ìš°)
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# 1) ëª¨ë¸ ë¡œë”© & ìµœì í™”
logging.info("Loading TTS model...")
tts_model = TTS(model_name="tts_models/en/vctk/vits", progress_bar=False, gpu=DEVICE.type=="cuda")
tts_model.model = tts_model.model.half()                       # FP16
tts_model.model = torch.jit.script(tts_model.model)            # JIT compile
tts_model.model.to(DEVICE)
logging.info(f"TTS model ready on {DEVICE}")

SAMPLE_RATE = 22050


# ìš”ì²­ ë°ì´í„° êµ¬ì¡°
class TTSRequest(BaseModel):
    text: str
    speaker: str = None


# ê°„ë‹¨ ë¬¸ì¥ ë¶„í•  (ë§ˆì¹¨í‘œ ê¸°ì¤€)
def split_sentences(text: str):
    # ë§ˆì¹¨í‘œ/ë¬¼ìŒí‘œ/ëŠë‚Œí‘œ ë’¤ì— ê³µë°±ìœ¼ë¡œ ë¶„í• 
    import re
    parts = re.split(r'([.?!])\s*', text)
    # ["Hello", ".", "How are you", "?"] â†’ ["Hello.", "How are you?"]
    sentences = []
    for i in range(0, len(parts)-1, 2):
        sentences.append((parts[i] + parts[i+1]).strip())
    if len(parts) % 2 == 1 and parts[-1].strip():
        sentences.append(parts[-1].strip())
    return sentences or [text]


@app.post("/api/tts")
async def synthesize(req: TTSRequest):
    if not req.text.strip():
        raise HTTPException(400, "No text provided")

    try:
        # 2) ë¬¸ì¥ ë‹¨ìœ„ ì²­í‚¹
        chunks = split_sentences(req.text)

        # ë©”ëª¨ë¦¬ ë²„í¼ì— ê²°ê³¼ ì´ì–´ ì“°ê¸°
        buffer = io.BytesIO()
        with wave.open(buffer, 'wb') as wf:
            wf.setnchannels(1)
            wf.setsampwidth(2)
            wf.setframerate(SAMPLE_RATE)

            for chunk in chunks:
                # 3) no_gradë¡œ ì¶”ë¡ 
                with torch.no_grad():
                    wav = tts_model.tts(chunk, speaker=req.speaker) \
                          if req.speaker else tts_model.tts(chunk)

                # í•©ì„± ê²°ê³¼ í•©ì¹˜ê¸°
                arr = np.array(wav)
                int16 = (np.clip(arr, -1, 1) * 32767).astype(np.int16)
                wf.writeframes(int16.tobytes())

        # 4) ìµœì¢… ë°”ì´íŠ¸ â†’ base64
        audio_bytes = buffer.getvalue()
        audio_base64 = base64.b64encode(audio_bytes).decode("utf-8")
        return JSONResponse({"audio": audio_base64})

    except Exception:
        logging.error("TTS processing error:\n" + traceback.format_exc())
        raise HTTPException(500, "TTS ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ")


if __name__ == "__main__":
    # ë¡œì»¬ ë””ë²„ê·¸ìš©: workers=1 ë¡œ ë©”ëª¨ë¦¬ ì ˆì•½
    uvicorn.run(
        "app:app",
        host="0.0.0.0",
        port=int(os.getenv("PORT", 5000)),
        workers=1,
        log_level="info",
    )
