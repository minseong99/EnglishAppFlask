#app.py
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
from fastapi.responses import JSONResponse
import base64
import io
import numpy as np
import torch
import wave
from TTS.api import TTS
import uvicorn
import logging

app = FastAPI()
logging.basicConfig(level=logging.INFO)

# ğŸš€ GPU í™œì„±í™” (ê°€ëŠ¥í•œ ê²½ìš°)
use_gpu = torch.cuda.is_available()
tts_model = TTS(model_name="tts_models/en/vctk/vits", progress_bar=False, gpu=use_gpu)
sample_rate = 22050

logging.info(f"TTS ëª¨ë¸ ë¡œë“œ ì„±ê³µ (GPU ì‚¬ìš©: {use_gpu})")

# ìš”ì²­ ë°ì´í„° êµ¬ì¡° ì •ì˜
class TTSRequest(BaseModel):
    text: str
    speaker: str = None  # ì„ íƒì  í™”ì

@app.post("/api/tts")
async def synthesize(request: TTSRequest):
    try:
        # TTS ë³€í™˜ ì‹¤í–‰
        wav = tts_model.tts(request.text, speaker=request.speaker) if request.speaker else tts_model.tts(request.text)
        
        # float [-1,1] -> int16 ë³€í™˜
        wav = np.array(wav)
        wav_int16 = (np.clip(wav, -1, 1) * 32767).astype(np.int16)

        # WAV íŒŒì¼ ë©”ëª¨ë¦¬ ì €ì¥
        buffer = io.BytesIO()
        with wave.open(buffer, 'wb') as wf:
            wf.setnchannels(1)
            wf.setsampwidth(2)
            wf.setframerate(sample_rate)
            wf.writeframes(wav_int16.tobytes())

        audio_bytes = buffer.getvalue()
        audio_base64 = base64.b64encode(audio_bytes).decode("utf-8")

        return JSONResponse(content={"audio": audio_base64})

    except Exception as e:
        logging.error(f"TTS í•©ì„± ì˜¤ë¥˜: {e}")
        raise HTTPException(status_code=500, detail="TTS ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ")

# ğŸš€ FastAPI ì„œë²„ ì‹¤í–‰
if __name__ == "__main__":
    uvicorn.run(app, host="0.0.0.0", port=5000, workers=4)  # ë©€í‹°í”„ë¡œì„¸ì‹± ì ìš©